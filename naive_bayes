## Saya akan buat video tutorialnya di Youtube. Untuk saat ini, silakan kunjungi dan subscribe channel saya -> https://www.youtube.com/channel/UCEf5r6lPK1oImal2gxZJllw
## I will make tutorial videos on Youtube. In the meantime, please visit and subscribe my channel -> https://www.youtube.com/channel/UCEf5r6lPK1oImal2gxZJllw


# Persiapan awal / Setting up things

download.file(url = "http://curl.haxx.se/ca/cacert.pem", destfile = "cacert.pem")

library(twitteR)

setup_twitter_oauth("aaaa",
                    "bbbb",
                    "cccc",
                    "dddd")
##################################################################################

# Akuisisi tweets / acquire tweets

tweets <- searchTwitter("kueri / query", n = 2000, lang = "id")

df_tweets <- twListToDF(tweets)
#################################################################################

# Buat file .csv / create .csv file

write.csv(df_tweets$text, file = "csv_tweets.csv", row.names = F)
##################################################################################

# Pre-processing di RStudio / Pre-processing at RStudio

sentiment        <- read.csv("csv_tweets.csv", sep = ";")
sentiment$text <- as.character(sentiment$text)
sentiment$text <- tolower(sentiment$text)
sentiment$text <- gsub("https://t.co/\\w+", " ", sentiment$text)
sentiment$text <- gsub("@\\w+", " ", sentiment$text)
sentiment$text <- gsub("[[:punct:]]|.", " ", sentiment$text)
sentiment$text <- gsub("[[:digit:]]", " ", sentiment$text)

library(tm)
stopword_indo <- read.csv("id.stopwords.02.01.2016.csv", header = FALSE)
stopword_indo <- as.character(stopword_indo$V1)
stopword_indo <- c(stopword_indo, stopwords())
sentiment$text <- removeWords(sentiment$text, stopword_indo)
sentiment$text <- stripWhitespace(sentiment$text)
##################################################################################

# Vektorisasi / Vectorization

dtm_sentiment <- DocumentTermMatrix(
                    Vcorpus(
                        VectorSource(sentiment$text)
                    )
                )
##################################################################################

# Buat set data training dan testing / Create training and testing dataset

dtm_sentiment_latih <- dtm_sentiment[1:1800, ]
dtm_sentiment_uji   <- dtm_sentiment[1801:2000, ]

label_sentiment_latih <- sentiment[1:1800, ]$label
label_sentiment_uji   <- sentiment[1801:2000,]$label

konversi_jumlah <- function(x){
                       x <- ifelse(x > 0, "Ada",
                      "TAda")
                    }

sentiment_latih <- apply(dtm_sentiment_latih, MARGIN = 2, konversi_jumlah)
sentiment_uji   <- apply(dtm_sentiment_uji, MARGIN = 2, konversi_jumlah)
##################################################################################

# Tahap training / Training step

library(e1071)

pengklas_sentiment <- naiveBayes(sentiment_latih,label_sentiment_latih)
prediksi_sentiment <- predict(pengklas_sentiment,sentiment_uji) 
##################################################################################

# Buat tabulasi silang / Create cross-table

library(gmodels)

CrossTable(prediksi_sentimen, label_sentimen_uji,
           prop.chisq = F, prop.t = F,
           dnn = c('terprediksi', 'manual'))
##################################################################################

# Visualisasi / Visualization

pie(prop.table(table(prediksi_sentimen)),
    labels = paste(pengklas_sentimen$levels,
                   "\n", table(prediksi_sentimen), sep = " "),
    col = rainbow(4), main = "Diagram Hasil Analisis
                              \n (Berdasarkan Set Data Testing
                              \n Sebanyak 200 Teks Tweets)")
